{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/dRnudeHVUExO+Y3a01Zo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephxlp/PyTorch100Days/blob/main/W1DAY4_Binary_Image_Classifier_(Cats_vs_Dogs).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "W1DAY4: Binary Image Classifier (Cats vs Dogs)"
      ],
      "metadata": {
        "id": "RsulP_J8k_x4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description:\n",
        "\n",
        "- Train a binary classifier to distinguish between cat and dog images using CNN\n",
        "-This project introduces image folders, binary classification, CNN architecture and kaggle\n",
        "\n",
        "\n",
        "    - Goal: Classify input images as either cat or dog using a CNN."
      ],
      "metadata": {
        "id": "_U7PVUJjk31t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import userdata\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Setup logging ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# --- Image transformations ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# --- Set credentials ---\n",
        "os.environ['KAGGLE_USERNAME'] = 'josephexeter'\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('josephexeter')\n",
        "\n",
        "# --- Directory paths ---\n",
        "train_dir = '/content/train'\n",
        "cat_dir = os.path.join(train_dir, 'cat')\n",
        "dog_dir = os.path.join(train_dir, 'dog')\n",
        "test_dir = '/content/test'\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "logging.info(\"set up main variables\")"
      ],
      "metadata": {
        "id": "N8tvv90m1Q_s"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Download and organize dataset if needed ---\n",
        "if os.path.exists(cat_dir) and os.path.exists(dog_dir):\n",
        "    logging.info(\"Class directories already exist. Skipping setup.\")\n",
        "else:\n",
        "    logging.info(\"Downloading and extracting dataset...\")\n",
        "    os.system(\"kaggle competitions download -c dogs-vs-cats\")\n",
        "    if os.path.exists('dogs-vs-cats.zip'):\n",
        "        os.system(\"unzip -q -o dogs-vs-cats.zip\")\n",
        "    if os.path.exists('train.zip'):\n",
        "        os.system(\"unzip -q -o train.zip\")\n",
        "    if os.path.exists('test1.zip'):\n",
        "        os.system(\"unzip -q -o test1.zip\")\n",
        "\n",
        "    os.makedirs(cat_dir, exist_ok=True)\n",
        "    os.makedirs(dog_dir, exist_ok=True)\n",
        "\n",
        "    logging.info(\"Organizing training images...\")\n",
        "    for filename in os.listdir('/content/train'):\n",
        "        src = os.path.join('/content/train', filename)\n",
        "        if filename.startswith('cat.'):\n",
        "            shutil.move(src, os.path.join(cat_dir, filename))\n",
        "        elif filename.startswith('dog.'):\n",
        "            shutil.move(src, os.path.join(dog_dir, filename))\n",
        "\n",
        "    logging.info(\"Organizing test images...\")\n",
        "    for filename in os.listdir('/content/test1'):\n",
        "        shutil.move(os.path.join('/content/test1', filename), os.path.join(test_dir, filename))\n",
        "\n",
        "\n",
        "logging.info(f\"2. Donwloaded dataset:: train and test\")"
      ],
      "metadata": {
        "id": "h5CB-6el3XFY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('# --- Load datasets ---')\n",
        "dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "class_names = dataset.classes\n",
        "\n",
        "print('# --- Split into training and validation ---')\n",
        "val_size = int(0.2 * len(dataset))\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "UAC62s8R3a0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0002c32-d63b-43d6-a351-66fb013b5a45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# --- Load datasets ---\n",
            "# --- Split into training and validation ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# --- Custom Dataset for unlabeled test images ---')\n",
        "class UnlabeledImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.image_files[idx]\n",
        "\n",
        "test_ds = UnlabeledImageDataset(test_dir, transform=transform)\n",
        "test_dl = DataLoader(test_ds, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "zdypGlS73dev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462c6f1c-c882-4e66-ee28-0fa44d5a1788"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# --- Custom Dataset for unlabeled test images ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# --- Define CNN ---')\n",
        "class CatDogCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CatDogCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32 * 32 * 32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 32 * 32)\n",
        "        return torch.sigmoid(self.fc1(x))"
      ],
      "metadata": {
        "id": "GOcE7hhl3gxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9b194e-da13-4e18-e502-e29fa050fb54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# --- Define CNN ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# --- Training Setup ---')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CatDogCNN().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "logging.info(f\"Using device: {device}\")\n",
        "print(f'# --- Training Setup --- {device}')"
      ],
      "metadata": {
        "id": "LI-RcHqD3jsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d35862d-4b71-4cd4-b3e5-6de237923096"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# --- Training Setup ---\n",
            "# --- Training Setup --- cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# --- Training Loop ---')\n",
        "for epoch in range(7):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    progress_bar = tqdm(train_dl, desc=f\"Epoch {epoch+1}\", leave=False)\n",
        "\n",
        "    for images, labels in progress_bar:\n",
        "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = running_loss / len(train_dl)\n",
        "    logging.info(f\"Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "95OU44l-3mrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e69238-1a23-421e-f101-4adc3b2f6006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# --- Training Loop ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:   7%|â–‹         | 42/625 [00:03<00:55, 10.50it/s, loss=0.219]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# --- Validation Metrics ---')\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_dl:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images).cpu().numpy().flatten()\n",
        "        preds = (outputs > 0.5).astype(int)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds)\n",
        "\n",
        "logging.info(f\"Validation Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "logging.info(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "logging.info(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
        "logging.info(f\"F1 Score: {f1_score(y_true, y_pred):.4f}\")\n",
        "logging.info(f\"Confusion Matrix:\\n{confusion_matrix(y_true, y_pred)}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vThv9t023p0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_true, y_pred):.4f}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_true, y_pred)}\")"
      ],
      "metadata": {
        "id": "BL2R8gPe8abD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Predict on Test Set ---\n",
        "def predict_test(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, filenames in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images).cpu().numpy().flatten()\n",
        "            preds = (outputs > 0.5).astype(int)\n",
        "            for fname, pred in zip(filenames, preds):\n",
        "                predictions.append((fname, class_names[pred]))\n",
        "    return pd.DataFrame(predictions, columns=['filename', 'predicted_label'])\n",
        "\n",
        "# Generate test predictions\n",
        "test_predictions = predict_test(model, test_dl)\n",
        "test_predictions.head()"
      ],
      "metadata": {
        "id": "ofvzHiXI3ueb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a more complex model\n",
        "# yolo"
      ],
      "metadata": {
        "id": "cgNbVBLH8icq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBXiQ83RmZSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}